# Trabajo de Fin de Grado : Alejandro Acebo

En este trabajo se ha persiguido el desarrollo de una herramienta para analizar la calidad de los datos con objeto de que usuarios no expertos en la programaci√≥n puedan poner bajo an√°lisis la calidad de sus datos.

## üìÅ Estructura del Proyecto

```plaintext
TFG_Calidad_Datos/
‚îú‚îÄ‚îÄ Base de datos PostgreSQL/                # Base de datos para evaluaci√≥n pr√°ctica
‚îÇ   ‚îú‚îÄ‚îÄ ScriptFinal                          # Script de creaci√≥n de base de datos e introuducci√≥n de datos
‚îú‚îÄ‚îÄ DaqLity/                                 # Herramienta desarrollada, posteriormente se explica su instalaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ Desarrollo-GreatExpectations/            # Herramienta Great-Expectations analizada en la evaluaci√≥n pr√°ctica
‚îÇ   ‚îú‚îÄ‚îÄ great-expectations
|   |   ‚îú‚îÄ‚îÄ evaluacion-practica-ge.py        # Desarrollo de test para analizar la calidad de datos en Great-Expectations
|   |   ‚îú‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ ...
|‚îÄ‚îÄ Desarrollo-PyDeequ/
|   |‚îÄ‚îÄ evaluacion-practica-pydeequ.py       # Desarrollo de test para analizar la cadlidad de datos en PyDeequ
|‚îÄ‚îÄ README.me                                # Documentaci√≥n del proyecto
‚îî‚îÄ‚îÄ conjunto_test_plan_de_calidad.josn       # Conjunto de pruebas definidas en el plan de calidad recogidas en archivo JSON
```

##  DaqLity: Herramienta para el An√°lisis de la Calidad de los Datos

**DaqLity** es una herramienta interactiva desarrollada como parte de un Trabajo de Fin de Grado (TFG) en Ingenier√≠a Inform√°tica. Su objetivo principal es facilitar el an√°lisis y la visualizaci√≥n de la calidad de conjuntos de datos, empleando tecnolog√≠as como Apache Spark y Streamlit.

La aplicaci√≥n permite detectar posibles problemas de calidad en los datos, presentar informaci√≥n sobre las diferentes dimensiones de la calidad del dato y ofrecer una interfaz sencilla para su uso por parte de analistas y cient√≠ficos de datos no exportos en programaci√≥n.

---

## Im√°genes de la herramienta
![Formulario conexi√≥n fuente de datos](https://i.imgur.com/S8gJLGU.png)

![Interfaz principal herramienta](https://i.imgur.com/DKDGOxY.png)

![Visualizaci√≥n de la evoluci√≥n de varios an√°lisis](https://i.imgur.com/qsJbzfj.png)

---
## ‚öôÔ∏è Instalaci√≥n y Puesta en Marcha

### 1. Clonar el repositorio

Para obtener una copia local del proyecto, ejecutar:

```bash
git clone https://github.com/AlejandroAcebo/TFG_Calidad_Datos/
```

### 2. Acceder al directorio de la herramienta

Despu√©s de clonar el repositorio, accede al directorio principal de la herramienta:

```bash
cd ./TFG_Calidad_Datos/DaqLity
```

### OPCI√ìN UBUNTU
### 3. Crear un entorno virtual (opcional pero recomendable)

Se recomienda crear un entorno virtual para aislar las dependencias del proyecto:

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3.1. Instalar las dependencias necesarias

Ejecuta los siguientes comandos para actualizar el sistema, instalar Java y configurar las variables de entorno, y finalmente instalar las dependencias de Python necesarias:

```bash
sudo apt update
sudo apt install openjdk-17-jdk
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
export PATH=$JAVA_HOME/bin:$PATH
pip install streamlit
pip install pyspark==3.5.0
pip install --upgrade setuptools wheel
pip install plotly
pip install pydeequ
```

Descarga de los conectores jdbc de bases relacionales: PostgreSQL, MySQL, SQL Server y MariaDB
```bash
mkdir jars && cd jars/
wget https://jdbc.postgresql.org/download/postgresql-42.6.0.jar
wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.30/mysql-connector-java-8.0.30.jar
wget https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/12.2.0.jre8/mssql-jdbc-12.10.0.jre8.jar
wget https://repo1.maven.org/maven2/org/mariadb/jdbc/mariadb-java-client/3.1.4/mariadb-java-client-3.1.4.jar

```

### OPCI√ìN WINDOWS
### 4. Instalar dependencias necesarias

Gu√≠a de Instalaci√≥n y Configuraci√≥n de Java, Spark y Hadoop en Windows


Instalar Java JDK 17
```bash
Descargar desde:
https://www.oracle.com/java/technologies/javase/jdk17-archive-downloads.html

Instalar en:
C:\Program Files\Java\jdk-17

Configurar variables de entorno:
JAVA_HOME ‚Üí C:\Program Files\Java\jdk-17

Agregar a Path:
%JAVA_HOME%\bin
```

Instalar Apache Spark
```bash
Descargar desde:
https://spark.apache.org/downloads.html

Versi√≥n: Spark 3.5.0
Package: Pre-built for Apache Hadoop 3

Descomprimir en:
C:\spark\spark-3.5.0-bin-hadoop3

Configurar variables de entorno:
SPARK_HOME ‚Üí C:\spark\spark-3.5.0-bin-hadoop3

Agregar a Path:
%SPARK_HOME%\bin
```

Instalar winutils.exe (soporte Hadoop en Windows)

```bash
Crear carpeta:
C:\hadoop\bin

Descargar winutils.exe compatible con Hadoop 3.x:
https://github.com/cdarlint/winutils

Copiar winutils.exe en:
C:\hadoop\bin

Configurar variable de entorno:
HADOOP_HOME ‚Üí C:\hadoop

Agregar a Path:
%HADOOP_HOME%\bin
```

Una vez instalado todo esto reiniciar la terminal y acceder desde tu IDE de python preferido a la terminal y ejecutar:

```bash
pip install streamlit
pip install pyspark==3.5.0
pip install --upgrade setuptools wheel
pip install plotly
pip install pydeequ
```

Seguido instalar los archivos jar de los jdbc necesarios y meterlos en una carpeta llamada "jars" dentro del proyecto, que habr√° que crear:

```bash

mkdir jars && cd jars
https://github.com/microsoft/mssql-jdbc/releases/download/v12.10.0/mssql-jdbc-12.10.0.jre8.jar
https://jdbc.postgresql.org/download/postgresql-42.6.0.jar
https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/12.2.0.jre8/mssql-jdbc-12.10.0.jre8.jar
https://repo1.maven.org/maven2/org/mariadb/jdbc/mariadb-java-client/3.1.4/mariadb-java-client-3.1.4.jar
```

### 5. Ejecutar la herramienta

Para iniciar la aplicaci√≥n, ejecuta el siguiente comando en el directorio de la herramienta:

```bash
streamlit run UI.py
```

### 6. Acceder a la interfaz web

Al ejecutar la herramienta, en la terminal aparecer√°n dos URLs:

- **Local URL:** permite acceder desde el navegador del equipo local, por ejemplo:
_http://localhost:8501_

- **Network URL:** Esta URL permite acceder a la aplicaci√≥n desde otro dispositivo que est√© conectado a la misma red local. Por ejemplo:
_http://192.168.X.X:8501_

